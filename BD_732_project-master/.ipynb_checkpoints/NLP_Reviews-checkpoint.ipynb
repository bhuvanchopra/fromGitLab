{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing -- Big Data Programming 1 Project\n",
    "## Machine Learning model to predict the rating based on reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "# do the import for stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#Importing CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# Importing some models to test\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "# imports for model evaluations\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Multiprocessing\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to process the text reviews\n",
    "def process_text(raw_text):\n",
    "    # Check for the punctuations \n",
    "    nopunc = [char for char in raw_text \n",
    "              if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters \n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Remove stopwords (if any)\n",
    "    return [word for word in nopunc.split() \n",
    "            if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rating from stars to good & excellent -- We can leave it with 5 stars as well. \n",
    "def define_rating_class(rating):\n",
    "    stars = [1,2,3]\n",
    "    if rating in stars:\n",
    "        #print (rating)\n",
    "        return 'good'\n",
    "    else:\n",
    "        return 'Excellent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating our model -- insted of printing, we can save the report as saperate file as well\n",
    "def model_evaluation(label, y_test, pred):\n",
    "    print (label)\n",
    "    print (confusion_matrix(y_test, pred))\n",
    "    print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with pipeline feature for model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def main(x): # x just to run pool, a test case.\n",
    "def main():\n",
    "    #%%time\n",
    "    df1 = pd.read_csv('data_clean.csv')\n",
    "    \n",
    "#    X_train, X_test = train_test_split(df1,\n",
    "#                                       test_size=0.001,\n",
    "#                                       random_state=42)\n",
    "#    df1 = X_test\n",
    "    df = df1[['rating','reviewText', 'rev_len']]\n",
    "    \"\"\"let's deal with the possible NaN \n",
    "    Dropping all with NaN\n",
    "    \"\"\"\n",
    "    df=df.dropna()\n",
    "    \"\"\"Spliting rating to good (1 to 3 stars) and \n",
    "    excellent (4 & 5 Stars)\"\"\"\n",
    "    df['rating']= df['rating'].apply(define_rating_class)\n",
    "    #Tokenization\n",
    "    \"\"\"Let's apply process_text() to the sms column in \n",
    "    our dataframe to get the tokens\n",
    "    \"\"\"    \n",
    "    #df['reviewText'].apply(process_text);\n",
    "    \"\"\"Let's fit the CountVectorizer() to reviewText column \n",
    "    of our dataframe.\n",
    "    \"\"\"\n",
    "    X = df['reviewText']\n",
    "    y = df['rating']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    pipelines = [\n",
    "        ('MultinomialNB_model', Pipeline([\n",
    "            ('bow', CountVectorizer(analyzer = process_text)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('model_nb', MultinomialNB())])\n",
    "        ),\n",
    "        ('LogisticRegression_model', Pipeline([\n",
    "            ('bow', CountVectorizer(analyzer = process_text)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('model_nb', LogisticRegression())])\n",
    "        ),\n",
    "        ('RandomForest_model', Pipeline([\n",
    "            ('bow', CountVectorizer(analyzer = process_text)),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('model_nb', RandomForestClassifier())])\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    for label, pipeline in pipelines:\n",
    "        pipeline.fit(X_train,y_train)\n",
    "        pred = pipeline.predict(X_test)\n",
    "        \"\"\"Evaluation\"\"\"\n",
    "        model_evaluation(label, y_test, pred)\n",
    "    #%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB_model\n",
      "[[25404    11]\n",
      " [ 7025    66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.78      1.00      0.88     25415\n",
      "        good       0.86      0.01      0.02      7091\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     32506\n",
      "   macro avg       0.82      0.50      0.45     32506\n",
      "weighted avg       0.80      0.78      0.69     32506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_model\n",
      "[[24545   870]\n",
      " [ 3358  3733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.88      0.97      0.92     25415\n",
      "        good       0.81      0.53      0.64      7091\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     32506\n",
      "   macro avg       0.85      0.75      0.78     32506\n",
      "weighted avg       0.86      0.87      0.86     32506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_model\n",
      "[[25083   332]\n",
      " [ 5771  1320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.81      0.99      0.89     25415\n",
      "        good       0.80      0.19      0.30      7091\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     32506\n",
      "   macro avg       0.81      0.59      0.60     32506\n",
      "weighted avg       0.81      0.81      0.76     32506\n",
      "\n",
      "4049.3036601543427\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    p = Process(target=main)#, args=('bob',))\n",
    "    p.start() \n",
    "    p.join()\n",
    "#    main( )\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Link to understand classification report.<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anything above is final. below are all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB_model\n",
      "[[25404    11]\n",
      " [ 7025    66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.78      1.00      0.88     25415\n",
      "        good       0.86      0.01      0.02      7091\n",
      "\n",
      "   micro avg       0.78      0.78      0.78     32506\n",
      "   macro avg       0.82      0.50      0.45     32506\n",
      "weighted avg       0.80      0.78      0.69     32506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_model\n",
      "[[24545   870]\n",
      " [ 3358  3733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.88      0.97      0.92     25415\n",
      "        good       0.81      0.53      0.64      7091\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     32506\n",
      "   macro avg       0.85      0.75      0.78     32506\n",
      "weighted avg       0.86      0.87      0.86     32506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_model\n",
      "[[25062   353]\n",
      " [ 5789  1302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.81      0.99      0.89     25415\n",
      "        good       0.79      0.18      0.30      7091\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     32506\n",
      "   macro avg       0.80      0.58      0.59     32506\n",
      "weighted avg       0.81      0.81      0.76     32506\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "map() missing 1 required positional argument: 'iterable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-19e5528a5829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#p.starmap(main, [1,2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#    p = Process(target=main)#, args=('bob',))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#p.start()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: map() missing 1 required positional argument: 'iterable'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    with Pool(5) as p:\n",
    "        #p.starmap(main, [1,2])\n",
    "        p.map(main())#,[1])\n",
    "#    p = Process(target=main)#, args=('bob',))\n",
    "    #p.start() \n",
    "    #p.join()\n",
    "#    main( )\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1975250244140625e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543562593.158515\n"
     ]
    }
   ],
   "source": [
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation without Pipeline feature - Draft 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    df1 = pd.read_csv('data_clean.csv')\n",
    "    X_train, X_test = train_test_split(df1,\n",
    "                                       test_size=0.5,\n",
    "                                       random_state=42)\n",
    "    df1 = X_test\n",
    "    df = df1[['rating','reviewText', 'rev_len']]\n",
    "    \"\"\"let's deal with the possible NaN \n",
    "    Dropping all with NaN\n",
    "    \"\"\"\n",
    "    df=df.dropna()\n",
    "    \"\"\"Spliting rating to good (1 to 3 stars) and \n",
    "    excellent (4 & 5 Stars)\"\"\"\n",
    "    df['rating']= df['rating'].apply(define_rating_class)\n",
    "    #Tokenization\n",
    "    \"\"\"Let's apply process_text() to the sms column in \n",
    "    our dataframe to get the tokens\n",
    "    \"\"\"    \n",
    "    df['reviewText'].apply(process_text);\n",
    "    \"\"\"Let's fit the CountVectorizer() to reviewText column \n",
    "    of our dataframe.\n",
    "    \"\"\"\n",
    "    bow_transformer = CountVectorizer(analyzer=process_text\n",
    "                                     ).fit(df['reviewText'])\n",
    "    \"\"\"Now, Let's move on and use .transform with bow_transformer\n",
    "    and transform the entire DataFrame of sms corpus.\n",
    "    \"\"\"\n",
    "    df_bow = bow_transformer.transform(df['reviewText'])\n",
    "    #TfidfTransformer\n",
    "    \"\"\"#Let's create an instance for TfidfTransformer \n",
    "    and fit to the df_bow\n",
    "    \"\"\"\n",
    "    tfidf_trans = TfidfTransformer()\n",
    "    tfidf_trans.fit(df_bow)\n",
    "    \"\"\"lets transfer our entire BoW \"sms_bow\" to TF-IDF corpus! Instead \n",
    "    of passing a single sms as a BoW, we will pass the entire corpus.\n",
    "    \"\"\"\n",
    "    df_tfidf = tfidf_trans.transform(df_bow)\n",
    "    \"\"\"\n",
    "    Naive Bayes is considered as a good choice in text retrieval community.\n",
    "    With appropriate pre-processing, Naive Bayes is competitive in this domain\n",
    "    with more advanced methods including support vector machines.\n",
    "    Let's use the one which is accepted by the experts as a better choice!\n",
    "    We have imported the multinomial Naive Bayes model above, \"MultinomialNB\" from sklearn.\n",
    "    Let's create instance for MultinomialNB now!\n",
    "    \"\"\"\n",
    "    rating_predictions = MultinomialNB()\n",
    "    \"\"\"Train test split\"\"\"\n",
    "    X = df_tfidf\n",
    "    y = df['rating']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.33, \n",
    "        random_state=42)\n",
    "    \"\"\"training on train data\"\"\"\n",
    "    rating_predictions.fit(X_train, y_train)\n",
    "    \"\"\"predictions for the test data\"\"\"\n",
    "    pred = rating_predictions.predict(X_test)\n",
    "    \"\"\"Evaluation\"\"\"\n",
    "    model_evaluation(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517   0]\n",
      " [134   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.79      1.00      0.89       517\n",
      "        good       0.00      0.00      0.00       134\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       651\n",
      "   macro avg       0.40      0.50      0.44       651\n",
      "weighted avg       0.63      0.79      0.70       651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple implementation with notebook - individual pipeline for each model - Draft 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = df1[['rating','reviewText', 'rev_len']]\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['rating']= df['rating'].apply(define_rating_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Excellent    1554\n",
       "good          417\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rev_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79950</th>\n",
       "      <td>good</td>\n",
       "      <td>I know I have had the mug since Feb, but it ha...</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83548</th>\n",
       "      <td>good</td>\n",
       "      <td>I bought these ant baits based on the reviews ...</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57790</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Well, the Kelty guys don't need to be speciall...</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18965</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>The trampoline arrived quickly and the box was...</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33517</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>The Flex belt pads i ordered was the same i re...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating                                         reviewText  rev_len\n",
       "79950       good  I know I have had the mug since Feb, but it ha...      248\n",
       "83548       good  I bought these ant baits based on the reviews ...     1135\n",
       "57790  Excellent  Well, the Kelty guys don't need to be speciall...      874\n",
       "18965  Excellent  The trampoline arrived quickly and the box was...     2998\n",
       "33517  Excellent  The Flex belt pads i ordered was the same i re...      101"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the message are 'NaN' which generate error, Let's create another dataframe to see what are those messages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how manay are NaN!\n",
    "sum(pd.isnull(df['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Whic are NaN\n",
    "df3 = df[pd.isnull(df['reviewText'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rev_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rating, reviewText, rev_len]\n",
       "Index: []"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#any NaN in rating?\n",
    "sum(pd.isnull(df['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping all with NaN\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.isnull(df['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rev_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79950</th>\n",
       "      <td>good</td>\n",
       "      <td>I know I have had the mug since Feb, but it ha...</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83548</th>\n",
       "      <td>good</td>\n",
       "      <td>I bought these ant baits based on the reviews ...</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57790</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>Well, the Kelty guys don't need to be speciall...</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18965</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>The trampoline arrived quickly and the box was...</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33517</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>The Flex belt pads i ordered was the same i re...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating                                         reviewText  rev_len\n",
       "79950       good  I know I have had the mug since Feb, but it ha...      248\n",
       "83548       good  I bought these ant baits based on the reviews ...     1135\n",
       "57790  Excellent  Well, the Kelty guys don't need to be speciall...      874\n",
       "18965  Excellent  The trampoline arrived quickly and the box was...     2998\n",
       "33517  Excellent  The Flex belt pads i ordered was the same i re...      101"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import string\n",
    "#do the import for stopwords\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text(raw_text):\n",
    "    # Check for the punctuations \n",
    "    nopunc = [char for char in raw_text \n",
    "              if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters \n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Remove stopwords (if any)\n",
    "    return [word for word in nopunc.split() \n",
    "            if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization<br>\n",
    "Let's apply process_text() to the reviews column in our dataframe to get the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['reviewText'].apply(process_text);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Importing CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's fit the CountVectorizer() to reviewText column of our dataframe.\n",
    "bow_transformer = CountVectorizer(\n",
    "    analyzer=process_text).fit(df['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's move on and use .transform with bow_transformer and transform the entire DataFrame of sms corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bow = bow_transformer.transform(df['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn provides a tool TfidfTransformer, let's do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing import \n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#Let's create an instance for TfidfTransformer and fit to the df_bow\n",
    "tfidf_trans = TfidfTransformer()\n",
    "tfidf_trans.fit(df_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets transfer our entire BoW \"sms_bow\" to TF-IDF corpus! \n",
    "Instead of passing a single sms as a BoW, we will pass the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tfidf = tfidf_trans.transform(df_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1971, 11680)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the shape of sms_tfidf\n",
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we have transformed our data into its vector form, we can train our Machine Learning algorithm.\n",
    "Its a rating predictions, a classification problem.<br>\n",
    "Naive Bayes is considered as a good choice in text retrieval. With appropriate pre-processing, Naive Bayes is competitive in this domain with more advanced methods including support vector machines.<br>\n",
    "Let's work with multinomial Naive Bayes model, and then explore others for comparisons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's do the import for Naive Bayes\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "# creating instance\n",
    "rating_predictions = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "#from sklearn.model_selection import train_test_split \n",
    "X = df_tfidf\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training on train data\n",
    "rating_predictions.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions for the test data\n",
    "pred = rating_predictions.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517   0]\n",
      " [134   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.79      1.00      0.89       517\n",
      "        good       0.00      0.00      0.00       134\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       651\n",
      "   macro avg       0.40      0.50      0.44       651\n",
      "weighted avg       0.63      0.79      0.70       651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "print (confusion_matrix(y_test, pred))\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Pipeline for each model<br>\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. We can set up all the transformation, we did during the text processing, in a single unit using pipeline feature of scikit-learn. Rather than doing all steps one-by-one, we can then call that single unit for our data processing. In this way, we save lots of time and there is no need to re-do all the transformation steps manually. A simple call of pipeline object, with stored steps, on the data will do all the processing in future. \n",
    "Let's see this will work on our dataset! Let's do the train_test_split() again using our raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_test_split() on the raw data\n",
    "X = df['reviewText']\n",
    "y = df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating pipeline, need to do import first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    # Tokenization using scikit's CountVectorizer \n",
    "    ('baw', CountVectorizer(analyzer=process_text)),  \n",
    "    \n",
    "    # Computing TF-IDF  -- weighted scores\n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    \n",
    "     # Naive Bayes classifier to train on TF-IDF vectors\n",
    "    ('model_nb', MultinomialNB()), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('baw', CountVectorizer(analyzer=<function process_text at 0x1a1adc92f0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None..._tf=False, use_idf=True)), ('model_nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Traing / Fitting using pipeline\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions for the test data\n",
    "pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517   0]\n",
      " [134   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.79      1.00      0.89       517\n",
      "        good       0.00      0.00      0.00       134\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       651\n",
      "   macro avg       0.40      0.50      0.44       651\n",
      "weighted avg       0.63      0.79      0.70       651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(y_test, pred))\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517   0]\n",
      " [133   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.80      1.00      0.89       517\n",
      "        good       1.00      0.01      0.01       134\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       651\n",
      "   macro avg       0.90      0.50      0.45       651\n",
      "weighted avg       0.84      0.80      0.71       651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('baw', CountVectorizer(analyzer=process_text)),  \n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    \n",
    "     # only change is RandomForestClassifier() \n",
    "    ('model', LogisticRegression()), \n",
    "])\n",
    "# training the model\n",
    "pipeline.fit(X_train,y_train)\n",
    "# doing predictions\n",
    "pred = pipeline.predict(X_test)\n",
    "#Evaluation\n",
    "print (confusion_matrix(y_test, pred))\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[509   8]\n",
      " [114  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Excellent       0.82      0.98      0.89       517\n",
      "        good       0.71      0.15      0.25       134\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       651\n",
      "   macro avg       0.77      0.57      0.57       651\n",
      "weighted avg       0.80      0.81      0.76       651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('baw', CountVectorizer(analyzer=process_text)),  \n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    \n",
    "     # only change is RandomForestClassifier() \n",
    "    ('model', RandomForestClassifier()), \n",
    "])\n",
    "\n",
    "# training the model\n",
    "pipeline.fit(X_train,y_train)\n",
    "# doing predictions\n",
    "pred = pipeline.predict(X_test)\n",
    "#Evaluation\n",
    "print (confusion_matrix(y_test, pred))\n",
    "print (classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is a rough work to see the multi-processing implementation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info(title):\n",
    "    print(title)\n",
    "    print('module name:', __name__)\n",
    "    print('parent process:', os.getppid())\n",
    "    print('process id:', os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data_clean.csv')\n",
    "df = df1[['rating','reviewText', 'rev_len']]\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['reviewText'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    info('function f')\n",
    "    df1 = pd.read_csv('data_clean.csv')\n",
    "    df = df1[['rating','reviewText', 'rev_len']]\n",
    "    df=df.dropna()\n",
    "    df['reviewText'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main line\n",
      "module name: __main__\n",
      "parent process: 2113\n",
      "process id: 7944\n",
      "function f\n",
      "module name: __main__\n",
      "parent process: 7944\n",
      "process id: 8190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-87-10f983715e87>\", line 6, in f\n",
      "    df['reviewText'].apply(process_text)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/pandas/core/series.py\", line 2355, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas/_libs/src/inference.pyx\", line 1569, in pandas._libs.lib.map_infer (pandas/_libs/lib.c:66440)\n",
      "  File \"<ipython-input-70-abd044477b15>\", line 11, in process_text\n",
      "    return [word for word in nopunc.split()\n",
      "  File \"<ipython-input-70-abd044477b15>\", line 12, in <listcomp>\n",
      "    if word.lower() not in stopwords.words('english')]\n",
      "  File \"/anaconda/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\", line 22, in words\n",
      "    return [line for line in line_tokenize(self.raw(fileids))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-4a05eb65c12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, args=('bob',))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/anaconda/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\", line 23, in <listcomp>\n",
      "    if not line.startswith(ignore_lines_startswith)]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    info('main line')\n",
    "    p = Process(target=f)#, args=('bob',))\n",
    "    p.start() \n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
